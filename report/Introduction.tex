\chapter{Introduction}
\label{chapterlabel1}
% Inline citation: \bibentry{example-citation}

\section{Aim}
This project aims to understand how to implement neural network architectures and how they can be implemented given the software available today. 
The intent behind this is to one day create a machine vision tool for understanding emotion. However, to get to that stage, one must first understand the basics of machine learning for image and video classification. 
The project is an exploratory one that follows my initial journey in understanding and implementing neural network architectures for video classification. 
It begins by first trying to recreate the models for action recognition in videos as presented in \bibentry{KarpathyCVPR14}.
 It goes on to explore various pre-trained models and looks for ways to improve the architecture, taking into account temporal features. 
It looks at multiple training algorithms and understanding the effects of some hyperparameters and some performance optimization method. However, it's primary focus is on the implementation of models and understanding the frameworks used. 

Due to the high computation power and long-running time needed for machine vision tasks, another aim of this project is to understand how to set up the training of these models on systems with better computer resources. 
This was accomplished by learning to set up batch jobs for model training on the UCL cluster, Myriad.
% It then hopes to explore the effects of temporal features on the simple model as dicussed in \citep{KarpathyCVPR14} as well as other topics such as the effects of image augmentation and normalization techniques and optimization techniques on model performance.
% Not an expert on the python programming language, there is a skill gain on this language as its used by the frameworks used to implement these models.


%Due to the rise in research in machine vision, there has been an increase in pretrained models available, the project also hopes to explore some of these models as see how they can be reused. %

%It implements the pre-trained models and models in  \citep{KarpathyCVPR14} using the Keras API and the TensorFlow framework. The project also looks to investigate how these frameworks  research also It also focuses and tries to understand how these frameworks work and how they can be used to implement these models.
% Another aim of the project will be to explore the difficulties with recreating popular models with the current software and hardware at hand.
% It also aims to give an understanding from a software engineering perspective on how to begin with constructing these models.
% The initial architectures will be based off those discussed in \citep{KarpathyCVPR14}, where different models are explored for large-scale video classification with convolutional neural networks.


\section{Context}
%todo find that othert large video dataset%
In the past few years, with the increase in large labelled datasets, there has been a growth in the available frames works and libraries used to create these various algorithms for various machine learning task.  One of these datasets, for example, is the Imagenet dataset as discussed in \citep{JiaDeng2009IAlh}. 
This dataset is organized according to the WordNet hierarchy. In this hierarchy, wordnet is a meaningful concept which could also be described by multiple words or word phrases which are called a "synset". 
In the Imagenet dataset, WordNet contains more than 100,000 synsets, where nouns are the majority of about 80,000 plus. ImageNet aims to provide an average of 1000 images per each synset with the goal to offer tens of millions of images per WordNet. 
For video data, one of the benchmark datasets is the YouTube-8M dataset, as discussed in \citep{45619}.  
The YouTube-8M  is one of the largest multi-label video classification dataset, composed of about 8 million videos on Youtube annotated with a vocabulary of 4803 visual entities.  

Some of these frameworks and libraries birth from this growth in datasets used for the advancement of machine learning include scikit-learn.  Scikit-learn is a python programming language based library with a long-range of user-friendly APIs for creating machine learning algorithms. For example, \citep{DBLPjournalscorrBuitinckLBPMGNPGGLVJHV13} details the use of scikit-learn, highlighting it's elegant APIs.  Some of which have, lead to growth in the implementation of models in the machine learning space. In the deep learning space for more sophisticated machine learning problems, surveys such as \citep{Nguyen2019} have been taken on the available libraries and frameworks for deep learning with large datasets. It also details the hardware requirements some of these frames works propose.
\citep{Wang2019}, is another survey that describes the more commonly used deep learning frameworks developed by large software houses such as Google, Facebook, and Microsoft, and those developed by the open source community such as Caffe, Caffe2, Tensorflow, MXNet, CNTK, Torch, PyTorch,  MatconvNet, Matlab deep learning and Deep learning tool box, Deeplearning4j to name a few.
    
For the purpose of this project, I will be looking at using TensorFlow and Keras libraries and APIs with python as the programming language for building and using popular pre-trained models. 
TensorFlow is a free and open-source software library developed by Google and released in November 2015 for dataflow and differentiable programming as described in \citep{8578572}. While Keras, as discussed in \citep{Lux:2019:OSC:3310195.3310202} is a high-level elegant neural networks API. 
It provides tools such as layer implementation, algorithm implementation and data augmentation functions for easy constructions of neural networks. It also provides access to popular pre-trained models, and it is capable of running on top of frameworks like TensorFlow, CNTK, or Theano. 
TensorFlow and Keras make for the perfect fit for the project, as they provide the tools needed for implementing neural network architectures for video classification.

Another concept that has helped with this growth of complexed models is the availability of computing power on cloud infrastructures. This is because of the memory and massive computational power needed by some of these models. One provider of this is Amazon's  AWS Deep Learning Containers (AWS DL Containers).
These are Docker images with pre-installed deep learning frameworks such as TensorFlow and pytorch for easy and fast implementation. Another provider is Google cloud which provides a range of CPU, GPUs and TPUs capability. 
This project uses the UCL Cluster, which provides an array of servers with varying RAM sizes,  CPU and GPU capability along with an extensive library of available software.  The clusters are needed as the project deals with machine vision models which are known to require a long running time.  
    
\section{Related Work}
%todo identify different applications and benchmark models
% talk abour related work here on other models for video classification double check the pedistrain dection paper% 
There is vast range of problems in which convolutional neural network(CNNs) architectures are used, some of which are in the image classification space which include problems such as object detection for example in pedestrian detection \citep{TomeD2016DCNN} systems, to speech  recognition problems and also facial and body recognition systems which are items in the human emotion recognition and human interaction space \cite{knyazev2017convolutional} .They have also been used in natural language processing for example with modelling sentences as explained in \cite{Kalchbrenner_2014}. 
Most importantly, CNNs have also been used for video classification for example by using the codec as a spatio-temporal Activity Sensor on videos as described in \citep{ChadhaA2017VCWC}. Apart from convolutional neural networks there are other machine learning methods used for example bag of words models \citep{10.1007978-3-642-28493-9_34}, this can be based on using local visual descriptors, most common of these are histogram of oriented gradients (HOG), histogram of optical flow (HOF) and motion boundary histograms (MBH) descriptors which are very powerful for classification but also computationally expensive as described in \citep{Uijlings2015}. Other methods use recurrent neural networks(RNNs) which is also used in the natural language processing space and in general for sequence data. Since videos are essentially sequence data, RNNs can be used in theory however because RNNs are difficult to train on high-dimensional inputs due to the large input-to-hidden weight matrix there has been some difficulty using them, however there is additional research in the space that has lead to competitive results such as that described in \citep{yang2017tensortrain} which factorizes the input-to-hidden weight matrix using Tensor-Train decomposition to help with efficiency of training these models.
% reference need for von Neumann bottleneck and https://cloud.google.com/blog/products/ai-machine-learning/what-makes-tpus-fine-tuned-for-deep-learning%
Also when running these models apart from architecture one has to also consider processing hardware as evaluated in \citep{wang2019benchmarking} as this has an effect performance. Devices range (Central processing units) CPUs, which reads each instruction from the software hence has to store all calculaculations internally on memory. This memory access becomes the downside of CPU architecture called the von Neumann bottleneck because each CPU's Arithmetic Logic Units (ALU) executes calculation one by one, accessing the memory every time, limiting the total throughput and consuming significant energy. Another is the GPU(Graphical processing units which uses thousands of ALUs(about 2,500â€“5,000) in a processor of ALUs which means it can then execute thousands of multiplications and additions simultaneously. However it still suffers from the von Neumann bottleneck because For every  calculation in the thousands of ALUs, GPU it still needs to access shared memory to read and store intermediate calculation results. The most recent device of late is the Google designed, TPU (Tensor Processing Unit), which is designed as a matrix processor specialized for neural network work loads and is not as affected by the von Neumann bottleneck because its' primary task is matrix processing hence it consist of thousands of multipliers and adders connected to each other directly to form a large physical matrix called the systolic array architecture. Hence calculations naturally flow through the architecture reducing memory access during calculation and as a result it has a high computational throughput on neural network calculations with much less power consumption and smaller footprint.
%   todo add how easy it is to implement to bring it all together
  
%   such as there is a range of models typically used such as -----, videos can also be looked and complication of images in frames which simple convolutional networks can be use to classify together with methods used to take into account the temporal features. 
  
%   talk about vido clasification
    % This models have produced great results when it comes to image classification as discussed further in papers such as \citep{MISHKIN201711}. The use of convolutional neural networks doesn't stop in the computer vision field with image classification and video classification but also extends to tas well as physiological data, speech to name a few.
    
% why tensor flow this is a good paper \citep{schrimpf2016i}

    % When looking to build most reasches beging by either devloping there own neural network and looking at the archetures of other. one of the issue faces is the the same computational pwoer and hypter paraametres found.


