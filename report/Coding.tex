\chapter{My Second Content Chapter}
\label{chapterlabel3}

\section{Coding}
% -	I’d suggest separating custom contributions to the code from set-up of the experiment. Currently, some things I’d expect in the latter chapter are here.
% -	Also, you don’t need to explicitly present all of your code. Better attach it, or provide a github link, and highlight only relevan parts if you need to.

     
The coding began by first importing the tensorflor and tensorflow dataset.

\begin{lstlisting}[language=Python, caption=Importing tensorflow libaries]
import tensorflow as tf
import tensorflow_datasets as tfds
\end{lstlisting}

Using the tensorflow dataset libary allowed for easy loading of the UCF101 dataset as seen below. The libary also provides a default recommeneded train and test dataset. It also provided an information object detailing the labal and dataset size for the train and test size. 
     
\begin{lstlisting}[language=Python, caption=Loading UCF101 dataset]
ucf101_dataset, ucf101_info = tfds.load(name="ucf101", with_info=True)
ucf101_train , ucf101_test = ucf101_dataset["train"], ucf101_dataset["test"]
\end{lstlisting}

% todo talk about batches and shuffling

Custom python helper methods where used for the formatting of the images in the frame from $256 \times 256 \times 3$ to $170 \times170 \times 3$ as suggested in \citep{KarpathyCVPR14}. Most layers needed to build the model where present in the keras API. Most models where implemented using the keras sequential model which is the simplest model to implement as it is a simply a linear stack of layers as seen below. The single frame layer for example was implemented as a keras sequential model by passing in a list of layers as seen in \ref{singleFrame} note that this can also be implemented by using the the keras API add method to add in layers. More complex architectures such as the slow fusion layer used the keras functional API which uses the fact that a layers is a callable instance that can be called on a tensor and then returns a tensor to build multi-output and multi-input models like the slow and late fusion model.

\begin{lstlisting}[language=Python, caption=Single Frame model implemetation, label=singleFrame]
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(96, (11,11), strides=3 , activation='relu', input_shape=(170, 170, 3)),

    l.MyLRNLayer(),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(256, (5,5), strides=1, activation='relu'),

    l.MyLRNLayer(),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(384, (3,3), strides=1, activation='relu'),

    tf.keras.layers.Conv2D(384, (3,3), strides=1, activation='relu'),
    tf.keras.layers.Conv2D(256, (3,3), strides=1, activation='relu'),

    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dense(101, activation='softmax')
])
\end{lstlisting}

%todo more on the difference between LRN and batch normalization%
Some custom layers where needed like the local response normalization layer as described in \citep{NIPS2012_4824}. This was because it was no longer available on the keras API. As the local response normalization is a non-trainable layer normalizes values in a feature map within a local making less adaptive. While its replacement batch normalization as discussed in \citep{ioffe2015batch} is a trainable normalization layer wich allows for a much higher learning rates and requires less care with initialization. Batch normalization in some cases is also said to eliminate the need for Dropout. 
Another benefit of the Keras API is how it allows for easy creation of a custom layers through inheritance from its keras layer class as seen in \ref{lrn}. Here since all the parameters of the LRN are fixed no training is required hence the layer is set to trainable false.
This implementation also utilizes the tensorflow nn API which holds a functions that can be applied to tensor. Fortunately it also offers a local response normalization layer function calculation which returns the normalized tensor hence this was wrapped in the keras layer object so it can be used in  keras sequential model to implement the models.

\begin{lstlisting}[language=Python, caption=Local response normalization layer implemetation, label=lrn]
class MyLRNLayer(tf.keras.layers.Layer):
    def __init__(self, depth_radius=5,bias=1,alpha=1,beta=0.5, **kwargs):
        #         self.output_dim = output_dim
        self.depth_radius = depth_radius
        self.bias = bias
        self.alpha = alpha
        self.beta = beta
        super(MyLRNLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        # Create a trainable weight variable for this layer.
        self.kernel = self.add_weight(name='kernel',
                                      shape=(None),
                                      initializer='uniform',
                                      trainable=False)
        super(MyLRNLayer, self).build(input_shape)  # Be sure to call this at the end

    def call(self, x):
         return tf.nn.local_response_normalization(x,self.depth_radius,self.bias,self.alpha,self.beta)
\end{lstlisting}


    \subsection{Optimizations}

    As mentioned previous, Karpathy's models uses the local response normalization \cite{ROBINSON20071631} also used in the alexnet paper\cite{NIPS2012_4824}, however this normalization is now considered obsolete and the batch normalization \cite{ioffe2015batch} is the new standards normalization layer with some optimization benefits. Hence the models were also re-constructed using the recommended batch normalization in order to compare the results.  
    
    Karpathy's paper also using downpour stochastic gradient descents with multiple distributed systems because the dataset used is much smaller than that used in \citep{KarpathyCVPR14}. It was decided to use the standardd stochastic gradient descents optimization offered by the keras API using the parameter values from \citep{KarpathyCVPR14} which set a learning rate of $1e^-3$, momentum of 0.9 and decay of $0.0005$. How this is was implemented can be seen in \ref{sdgKeras} 
    
    \begin{lstlisting}[language=Python, caption=Keras SGD optimization, label=sdgKeras]
    sgd = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9, decay=0.0005)
    \end{lstlisting}
    
    % what is this, it is gradient descet to do with multiple distributed systems (http://ruder.io/optimizing-gradient-descent/index.html#tensorflow%
    
    Keras also offers a range of optimization models such as Adam optimization as described in \citep{kingma2014adam} \citep{ruder2016overview} and the RMS prop optimization also described in \citep{ruder2016overview}. These two optimization where tested against some models to explore changes in performance.
    
    %todo explain more  sparse_categorical_crossentropy and get reference for categorical crossentropy and sparse_categorical_crossentropy %
    The keras Api also provides a range of losses such as sparse categorical crossentropy. Which was used for most models. \citep{KarpathyCVPR14} doesnt not specify the loss function use however seen the categories where about 101 and give in integers sparse categorical crossentropy seemed like the best option from its close counterpart categorical crossentropy which is also used for multi classification but requires a one-hot encoded hence requiring the labels to be a vector of the length of labels. Keras also provides a utility method to covert label to categorical format when using categorical crossentropy loss. The option of loss was  passed as a parameter in the module compile function as seen in \ref{loss}. 
    
    \begin{lstlisting}[language=Python, caption=Compiling model with  sparse categorical crossentropy loss , label=loss]
    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
      \end{lstlisting}          
    
    
    The Keras Api provides other functions to help with performance such as dropout and data augmentation to help with over fitting. The Keras API offers the dropout in form of a keras layer that can be added after the layer requiring dropout. This was used in the case of the pretrained models as seen in \ref{dropout}
    
    \begin{lstlisting}[language=Python, caption=Application of dropout to pretrained models, label=dropout]
    model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.Dropout(0.5),
    global_average_layer,
    prediction_layer
])
  \end{lstlisting}

    %todo talk about data augementation%
    % Other hyperparamenrts used to improve performance included the  the learning rate, dropout, initial values and batch size. 
    
    \subsection{Image Augmentation}
     At first no augumentation was used for most of the models but it was later applied to most models. \citep{KarpathyCVPR14} paper talks about using the following data augumentataion to reduce overfiiting, the paper dicussed applying to all images cropping to center region, resizing them to $200 \times 200$ pixels then randomly sampling a $170 \times 170$ region, and finally randomly flipping the images horizontally with $50\%$ probability.  As the last step of preprocessing they also subtracted a constant value of 117 from raw pixel values, which was the approximate value of the mean of all pixels in  the images used. As much ofthese was tried to be recreted with the exception of rather that subtracting 117 from the images they were simply divided by 255 with is a popular technique of normalizing images. The keras API offers and image augumentation method as seen in \ref{kerasAug} howere this was a bit rescruted as it did not offer cropping functionality need like randon croping
     
         \begin{lstlisting}[language=Python, caption=keras image augumention, label=kerasAug]
    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
      \end{lstlisting}          
    

     
     \subsection{Computation Power}
     different learning rates for adam including the same usd for the sgd
     
    \subsection{Computation Power}
    Once familiar with the keras API the models where then moved to python scripts for running on the UCL clusters which offers a variety of RAM and CPU and GPU processing power. On the GPU simple models such as the single frame model ran between 40 - 30 minutes per epoch while more complex models such as the slow and late fusion model ran on average about 1 hour 45 minutes - 3 hours per epochs. As mentioned previously when using the UCL cluster interactive session using nodes with  and about 125GB of RAM showed the best performance speed wise.
